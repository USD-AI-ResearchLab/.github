<!-- ### Advancing AI innovation with sustainability at its core -->
<!-- ### Powering AI innovation from the heart of the Rushmore State -->
<!-- ### Where Coyotes howl and AI innovation powers sustainable futures -->
<!-- ### South Dakota's AI powerhouse: Sustainable innovation carved from the Rushmore spirit -->
<!-- ### Howling at the frontier of sustainable AI: The Rushmore State's research powerhouse -->
<!-- ### The Coyote's AI powerhouse: Sustainable innovation from the Rushmore State -->

<div align="Left">
  <img src="https://github.com/USD-AI-ResearchLab/.github/raw/main/logo.png" alt="University of South Dakota AI Research Lab" width="350"/>
  
  <span style="display: inline; font-size: 25em; style= margin-top: -2000px;"> </strong>***University of South Dakota AI Research Lab***</strong></span>
  <span style="font-size: 1.2em; color: #718096; margin-left: 10px;">(formerly <a href="https://github.com/2ai-lab/" style="color: #4299e1;">2ai lab</a>)</span>
</div>

<div align="left" style="margin-top: 20px;">
  <p>
    <strong>Mission:</strong> <em>The Coyote's AI powerhouse on Sustainable innovation from the heart of Rushmore State</em><br>
    <strong>Website:</strong> <a href="https://www.ai-research-lab.org/">ai-research-lab.org</a> • 
    <strong>Contact:</strong> <a href="usd.airesearch.lab@gmail.com">usd.airesearch.lab@gmail.com</a> • 
    <strong>Location:</strong> Vermillion, SD, USA
  </p>
</div>



We advance foundational AI and machine learning with a focus on sustainable, green computing to ensure efficiency and minimize carbon impact. Our interdisciplinary research spans computer vision, data mining, pattern recognition, and big data, impacting fields like healthcare, biometrics, forensics, speech, and IoT.
Join us as we drive AI innovation with sustainability at its core!
<br>



 Papers-with-Code 
-------

<!-- ------------------------------------------------------ -->

<!-- Papers-with-Code -->
<!-- ------------------------------------------------------ -->
<!-- Keep your look: white SVG separators, badge styling, same titles/subtitles -->

<td>
  <p align="center">
    <svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg>
  </p>

  <strong>Winsor‑CAM: Human‑Tunable Visual Explanations from Deep Networks via Layer‑Wise Winsorization</strong><br>
  <sub><em>Human‑tunable Grad‑CAM variant aggregating attributions across all conv layers; winsorization suppresses outliers for robust, coherent saliency maps.</em></sub><br>

  <!-- Paper -->
  <a href="https://arxiv.org/abs/2507.10846">
    <img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge">
  </a>

  <!-- Code (lab repo; may be private/unpublished yet) -->
  <a href="https://github.com/USD-AI-ResearchLab/Winsor-CAM-demo">
    <img alt="Code (lab repo)" src="https://img.shields.io/badge/Code-GitHub-0969DA?style=for-the-badge&logo=github">
  </a>
  <!-- NOTE: If this 404s, it’s likely private; leave as is for now to preserve look -->

  <p align="center">
    <svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg>
  </p>
</td>

<tr>
  <td width="50%">
    <p align="center">
      <svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4">
        <rect width="100%" height="4" fill="#ffffff"/>
      </svg>
    </p>
    <strong>DeepWhaleNet: Climate Change‑aware FFT‑based Deep Neural Network for Passive Acoustic Monitoring</strong><br>
    <sub><em>FFT‑based DNN for passive acoustic whale‑call detection with climate‑aware considerations; built for UPAM workflows.</em></sub><br>
    <!-- Paper (DOI) -->
    <a href="https://www.worldscientific.com/doi/10.1142/S0218001424590146">
      <img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge">
    </a>
    <!-- Code (GitHub) -->
    <a href="https://github.com/USD-AI-ResearchLab/DeepWhaleNet">
      <img alt="Code" src="https://img.shields.io/badge/Code-GitHub-0969DA?style=for-the-badge&logo=github">
    </a>
    <p align="center">
      <svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4">
        <rect width="100%" height="4" fill="#ffffff"/>
      </svg>
    </p>
  </td>

  <!-- spacer / optional paired card -->
  <td width="50%">
    <p align="center">
      <svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4">
        <rect width="100%" height="4" fill="#ffffff"/>
      </svg>
    </p>
  </td>
</tr>

<tr>
  <td width="50%">
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Non‑Uniform Illumination Attack for Fooling Convolutional Neural Networks</strong><br>
    <sub><em>NUI masks degrade CNNs; simple defense via NUI‑augmented training across CIFAR‑10, TinyImageNet, Caltech‑256.</em></sub><br>
    <a href="https://arxiv.org/abs/2409.03458"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="https://github.com/Akshayjain97/Non-Uniform_Illumination"><img alt="Code" src="https://img.shields.io/badge/Code-GitHub-0969DA?style=for-the-badge&logo=github"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>

  <td width="50%">
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Advances and Challenges in Meta‑Learning: A Technical Review</strong><br>
    <sub><em>Survey across few‑shot, transfer, domain shift, self‑supervision, federated/personalized, continual; open problems.</em></sub><br>
    <a href="https://arxiv.org/pdf/2307.04722"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20Advances%20and%20Challenges%20in%20Meta-Learning"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Advances in Deep Learning for Tuberculosis Screening using Chest X‑rays: The Last 5 Years Review</strong><br>
    <sub><em>Five‑year review of DL for TB CXR screening: datasets, methods, ROI localization, and challenges.</em></sub><br>
    <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9568934/"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20TB%20CXR%20Review"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>

  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Guest Editorial: Multimodal Learning in Medical Imaging Informatics</strong><br>
    <sub><em>Integrating heterogeneous clinical data (images, EHR, sensors, reports) for robust decision support.</em></sub><br>
    <a href="https://doi.org/10.1109/JBHI.2023.3241369"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20Multimodal%20Learning%20Editorial"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td width="50%">
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Cervical cancerous cell classification: opposition‑based harmony search for deep feature selection</strong><br>
    <sub><em>CNN features + opposition‑based harmony search; Pap smear & liquid‑based cytology.</em></sub><br>
    <a href="https://link.springer.com/article/10.1007/s13042-023-01872-z"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <!-- Author-lab code (DVLP @ JU) -->
    <a href="https://github.com/DVLP-CMATERJU/OBHS_DeepfeatureSelection"><img alt="Code (author lab)" src="https://img.shields.io/badge/Code-GitHub-0969DA?style=for-the-badge&logo=github"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>


  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>SecureFed: federated learning for lung abnormality analysis in chest X‑rays</strong><br>
    <sub><em>Secure aggregation for FL; robustness and fairness vs FedAvg/FedMGDA+/FedRAD on COVID‑19 CXRs.</em></sub><br>
    <a href="https://www.ai-research-lab.org/publication"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20SecureFed"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>AI tools for assessing human fertility using risk factors: a state‑of‑the‑art review</strong><br>
    <sub><em>Systematic review of 42 studies; highlights augmentation, features, explainability for fertility‑risk analysis.</em></sub><br>
    <a href="https://link.springer.com/article/10.1007/s10916-023-01983-8"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20Fertility%20Risk%20Factors%20Review"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>

  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Hybrid approach for text categorization: Bangla news</strong><br>
    <sub><em>Hybrid text+graph features on 14,373 Bangla articles; Naïve Bayes Multinomial; validated on English sets.</em></sub><br>
    <a href="https://digitalcommons.isical.ac.in/journal-articles/3686/"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20Bangla%20Hybrid%20Text%20Categorization"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Scale‑invariant preprocessing (ARES) to detect clusters of varying densities</strong><br>
    <sub><em>ARES rank transform enables KMeans/DBSCAN/Density‑Peak to recover varying‑density clusters more reliably.</em></sub><br>
    <a href="https://arxiv.org/abs/2401.11402"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20ARES%20Clustering%20Preprocessing"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>

  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Investigation of DNA discontinuity for detecting tuberculosis</strong><br>
    <sub><em>Automated pipeline to quantify DNA breaks using DNN + HMM on NCBI sequences; speed and accuracy gains.</em></sub><br>
    <a href="https://www.researchgate.net/publication/325272704_Investigation_of_DNA_Discontinuity_for_Detecting_Tuberculosis"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20DNA%20Discontinuity%20for%20TB"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>LIFA: Language identification from audio with LPCC‑G features</strong><br>
    <sub><em>LPCC‑G + Random Forest across 11 Indian languages (&gt;2,200 hours); robust under noise.</em></sub><br>
    <a href="https://openreview.net/forum?id=n8sraRGFAT"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20LIFA%20(LPCC-G)"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>

  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Male fertility detection on skewed data with sampling + ensembles</strong><br>
    <sub><em>14 re‑sampling schemes; best LightGBM + SMOTE‑ENN; strong CatBoost baseline without re‑sampling.</em></sub><br>
    <a href="https://www.worldscientific.com/doi/abs/10.1142/S0218001424510033"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20Male%20Fertility%20Sampling%20%2B%20Ensembles"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Shallow CNN for COVID‑19 outbreak screening using chest X‑rays</strong><br>
    <sub><em>Lightweight CNN achieves 99.69% accuracy and AUC 0.9995; very low false positives; 5‑fold CV.</em></sub><br>
    <a href="https://www.ai-research-lab.org/publication"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <a href="mailto:contact@ai-research-lab.org?subject=Request%20code%3A%20Shallow%20CNN%20for%20COVID-19%20CXR"><img alt="Request code" src="https://img.shields.io/badge/Request%20code-Email-6e7781?style=for-the-badge&logo=gmail"></a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<tr>
  <td>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
    <strong>Covid‑19 Imaging Tools: How Big Data is Big?</strong><br>
    <sub><em>Dataset size, augmentation, transfer learning, and model‑fit caveats for COVID‑19 imaging tools.</em></sub><br>
    <a href="https://link.springer.com/article/10.1007/s10916-021-01747-2"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
    <!-- Related code: widely used author repo aligned with this domain -->
    <a href="https://github.com/lindawangg/COVID-Net">
      <img alt="Code: COVID‑Net" src="https://img.shields.io/badge/%20code-GitHub-0969DA?style=for-the-badge&logo=github">
    </a>
    <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  </td>
</tr>

<td>
  <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
  <strong>SegFast‑V2: Semantic image segmentation with fewer parameters</strong><br>
  <sub><em>Compact encoder‑decoder with kernel factorization &amp; depthwise deconvs; CPU‑friendly yet competitive.</em></sub><br>
  <a href="https://link.springer.com/article/10.1007/s13042-019-00906-2"><img alt="Paper" src="https://img.shields.io/badge/Paper-0969DA?style=for-the-badge"></a>
  <a href="https://github.com/DVLP-CMATERJU/SegFast"><img alt="Code" src="https://img.shields.io/badge/Code-GitHub-0969DA?style=for-the-badge&logo=github"></a>
  <p align="center"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="4"><rect width="100%" height="4" fill="#ffffff"/></svg></p>
</td>
<!-- ------------------------------------------------------ -->







